{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Fase 4: Entrenamiento y Selección de Modelos de Clasificación\n",
    "\n",
    "## Objetivo del Notebook\n",
    "\n",
    "Este notebook constituye la cuarta fase del pipeline de mantenimiento predictivo para sistemas de moto-compresores. El objetivo principal es entrenar, evaluar y seleccionar un modelo de clasificación binaria capaz de predecir si ocurrirá una falla en los próximos 7 días, utilizando las características derivadas del proceso de ingeniería de características implementado en la fase anterior.\n",
    "\n",
    "### Metodología de Entrenamiento\n",
    "\n",
    "La metodología implementada se basa en principios fundamentales de machine learning para series temporales, priorizando:\n",
    "\n",
    "1. **División Cronológica de Datos**: Implementación de una división temporal que respete la naturaleza secuencial de los datos operacionales, evitando la fuga de información (data leakage) que comprometería la validez del modelo.\n",
    "\n",
    "2. **Manejo de Desbalance de Clases**: Aplicación de técnicas específicas para abordar la distribución desigual entre muestras de operación normal y muestras pre-falla, fundamental en aplicaciones de mantenimiento predictivo.\n",
    "\n",
    "3. **Evaluación Robusta**: Utilización de métricas de rendimiento apropiadas para clasificación desbalanceada, que proporcionen una evaluación objetiva de la capacidad predictiva del modelo.\n",
    "\n",
    "4. **Simplicidad Computacional**: Selección de algoritmos que mantengan un balance óptimo entre rendimiento predictivo y eficiencia computacional.\n",
    "\n",
    "### Librerías y Dependencias\n",
    "\n",
    "El desarrollo requiere las siguientes librerías especializadas:\n",
    "- **pandas, numpy**: Manipulación y procesamiento de datos\n",
    "- **pathlib**: Gestión de rutas del sistema de archivos\n",
    "- **joblib**: Serialización eficiente de modelos\n",
    "- **matplotlib, seaborn**: Visualización de resultados y métricas\n",
    "- **sklearn**: Algoritmos de machine learning, pipelines y métricas de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuración del entorno completada exitosamente\n",
      "Directorio de datos procesados: data/processed\n",
      "Directorio de modelos: data/models\n"
     ]
    }
   ],
   "source": [
    "# Importación de librerías fundamentales para manipulación de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Librerías para visualización de resultados\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuración de estilo para visualizaciones\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Importación de algoritmos de machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Importación de herramientas de pipeline y preprocesamiento\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Importación de métricas de evaluación para clasificación\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    roc_auc_score, \n",
    "    precision_recall_curve,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "# Definición de rutas del proyecto\n",
    "data_processed_path = Path('./data/processed')\n",
    "models_path = Path('./data/models')\n",
    "\n",
    "# Creación de directorio de modelos si no existe\n",
    "models_path.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Configuración del entorno completada exitosamente\")\n",
    "print(f\"Directorio de datos procesados: {data_processed_path}\")\n",
    "print(f\"Directorio de modelos: {models_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Paso 2: Carga y Preparación de Datos\n",
    "\n",
    "### Proceso de Carga de Dataset\n",
    "\n",
    "En esta etapa se procede a cargar el dataset resultante del proceso de ingeniería de características desarrollado en la fase anterior. El archivo `featured_dataset_for_modeling.parquet` contiene el conjunto completo de características derivadas, incluyendo:\n",
    "\n",
    "- **Características originales de sensores**: Variables operacionales directas del moto-compresor\n",
    "- **Características de ventanas móviles**: Estadísticos calculados sobre períodos temporales específicos\n",
    "- **Características de lag temporal**: Variables retardadas que capturan dependencias temporales\n",
    "- **Variable objetivo**: Indicador binario de proximidad a falla (ventana de 7 días)\n",
    "\n",
    "### Separación de Características y Variable Objetivo\n",
    "\n",
    "La preparación de datos requiere la separación clara entre la matriz de características (X) y el vector de variable objetivo (y). Esta separación es fundamental para el entrenamiento supervisado del modelo de clasificación, donde:\n",
    "\n",
    "- **X**: Contiene todas las características derivadas que el modelo utilizará para realizar predicciones\n",
    "- **y**: Contiene la variable binaria 'falla' que indica si la muestra está dentro del período de 7 días previo a una falla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado exitosamente desde: data/processed/featured_dataset_for_modeling.parquet\n",
      "Dimensiones del dataset: (19752, 144)\n",
      "Memoria utilizada: 11.00 MB\n",
      "\n",
      "=== Información General del Dataset ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 19752 entries, 2023-01-11 00:00:00 to 2025-04-12 23:00:00\n",
      "Columns: 144 entries, rpm to presion_descarga_diff_12H\n",
      "dtypes: float32(144)\n",
      "memory usage: 11.0 MB\n",
      "None\n",
      "\n",
      "=== Distribución de la Variable Objetivo 'falla' ===\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'falla'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/EMI/Trabajo_Grado/Miguel_Salazar/modelado/version1/proyecto_pdm/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'falla'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Análisis de la variable objetivo\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== Distribución de la Variable Objetivo \u001b[39m\u001b[33m'\u001b[39m\u001b[33mfalla\u001b[39m\u001b[33m'\u001b[39m\u001b[33m ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m target_distribution = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfalla\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.value_counts().sort_index()\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(target_distribution)\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mPorcentaje de muestras normales (0): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(target_distribution[\u001b[32m0\u001b[39m]\u001b[38;5;250m \u001b[39m/\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;250m \u001b[39m*\u001b[38;5;250m \u001b[39m\u001b[32m100\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/EMI/Trabajo_Grado/Miguel_Salazar/modelado/version1/proyecto_pdm/.venv/lib/python3.12/site-packages/pandas/core/frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/EMI/Trabajo_Grado/Miguel_Salazar/modelado/version1/proyecto_pdm/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'falla'"
     ]
    }
   ],
   "source": [
    "# Carga del dataset con características de ingeniería\n",
    "dataset_path = data_processed_path / 'featured_dataset_for_modeling.parquet'\n",
    "\n",
    "try:\n",
    "    df = pd.read_parquet(dataset_path)\n",
    "    print(f\"Dataset cargado exitosamente desde: {dataset_path}\")\n",
    "    print(f\"Dimensiones del dataset: {df.shape}\")\n",
    "    print(f\"Memoria utilizada: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: No se encontró el archivo {dataset_path}\")\n",
    "    print(\"Asegúrese de haber ejecutado el notebook 03_feature_engineering.ipynb\")\n",
    "    raise\n",
    "\n",
    "# Verificación de la estructura del dataset\n",
    "print(\"\\n=== Información General del Dataset ===\")\n",
    "print(df.info())\n",
    "\n",
    "# Análisis de la variable objetivo\n",
    "print(\"\\n=== Distribución de la Variable Objetivo 'falla' ===\")\n",
    "target_distribution = df['falla'].value_counts().sort_index()\n",
    "print(target_distribution)\n",
    "print(f\"\\nPorcentaje de muestras normales (0): {(target_distribution[0] / len(df) * 100):.2f}%\")\n",
    "print(f\"Porcentaje de muestras pre-falla (1): {(target_distribution[1] / len(df) * 100):.2f}%\")\n",
    "print(f\"Ratio de desbalance: {target_distribution[0] / target_distribution[1]:.1f}:1\")\n",
    "\n",
    "# Separación de características y variable objetivo\n",
    "print(\"\\n=== Preparación de Matrices de Entrenamiento ===\")\n",
    "\n",
    "# Definición de la matriz de características (X)\n",
    "# Excluimos la columna 'falla' ya que es nuestra variable objetivo\n",
    "feature_columns = [col for col in df.columns if col != 'falla']\n",
    "X = df[feature_columns].copy()\n",
    "\n",
    "# Definición del vector objetivo (y)\n",
    "y = df['falla'].copy()\n",
    "\n",
    "print(f\"Matriz de características (X): {X.shape}\")\n",
    "print(f\"Vector objetivo (y): {y.shape}\")\n",
    "print(f\"Número de características disponibles: {len(feature_columns)}\")\n",
    "\n",
    "# Verificación de valores faltantes en características\n",
    "missing_values = X.isnull().sum().sum()\n",
    "print(f\"Valores faltantes en características: {missing_values}\")\n",
    "\n",
    "if missing_values > 0:\n",
    "    print(\"\\nCaracterísticas con valores faltantes:\")\n",
    "    missing_by_column = X.isnull().sum()\n",
    "    print(missing_by_column[missing_by_column > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Paso 3: División Cronológica de Datos (Time-Based Split)\n",
    "\n",
    "### Importancia Crítica de la División Temporal\n",
    "\n",
    "La división de datos en series temporales requiere un enfoque metodológicamente diferente al utilizado en problemas de clasificación estándar. La función `train_test_split` de scikit-learn con `shuffle=True` es **fundamentalmente incorrecta** para datos de series temporales por las siguientes razones:\n",
    "\n",
    "#### Problemas de la División Aleatoria:\n",
    "\n",
    "1. **Fuga de Información (Data Leakage)**: Una división aleatoria permite que el modelo acceda a información futura durante el entrenamiento, creando una ventaja artificial que no existiría en un escenario de predicción real.\n",
    "\n",
    "2. **Validación No Realista**: En aplicaciones industriales de mantenimiento predictivo, el modelo debe predecir eventos futuros basándose únicamente en datos históricos. Una división aleatoria no simula esta condición operacional.\n",
    "\n",
    "3. **Sobreestimación del Rendimiento**: Los resultados obtenidos con división aleatoria tienden a sobrestimar significativamente la capacidad predictiva real del modelo.\n",
    "\n",
    "#### Metodología de División Cronológica:\n",
    "\n",
    "La división cronológica implementada respeta la naturaleza secuencial de los datos operacionales, utilizando un punto de corte temporal que separa:\n",
    "\n",
    "- **Conjunto de Entrenamiento**: Datos históricos (80% inicial del dataset)\n",
    "- **Conjunto de Prueba**: Datos más recientes (20% final del dataset)\n",
    "\n",
    "Esta metodología simula fielmente el escenario operacional donde el modelo predice fallas futuras basándose únicamente en el historial de operación disponible hasta el momento de la predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Implementación de División Cronológica ===\n",
      "Tamaño total del dataset: 19752 muestras\n",
      "Punto de corte temporal: índice 15801\n",
      "Proporción de entrenamiento: 80.0%\n",
      "Proporción de prueba: 19.999999999999996%\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProporción de prueba: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(\u001b[32m1\u001b[39m-train_size)*\u001b[32m100\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# División cronológica de características\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m X_train = \u001b[43mX\u001b[49m.iloc[:split_index].copy()\n\u001b[32m     16\u001b[39m X_test = X.iloc[split_index:].copy()\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# División cronológica de variable objetivo\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# Implementación de división cronológica de datos\n",
    "\n",
    "print(\"=== Implementación de División Cronológica ===\")\n",
    "\n",
    "# Definición del punto de corte temporal (80% para entrenamiento)\n",
    "train_size = 0.8\n",
    "split_index = int(len(df) * train_size)\n",
    "\n",
    "print(f\"Tamaño total del dataset: {len(df)} muestras\")\n",
    "print(f\"Punto de corte temporal: índice {split_index}\")\n",
    "print(f\"Proporción de entrenamiento: {train_size*100}%\")\n",
    "print(f\"Proporción de prueba: {(1-train_size)*100}%\")\n",
    "\n",
    "# División cronológica de características\n",
    "X_train = X.iloc[:split_index].copy()\n",
    "X_test = X.iloc[split_index:].copy()\n",
    "\n",
    "# División cronológica de variable objetivo\n",
    "y_train = y.iloc[:split_index].copy()\n",
    "y_test = y.iloc[split_index:].copy()\n",
    "\n",
    "print(f\"\\n=== Dimensiones de los Conjuntos Resultantes ===\")\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "print(f\"y_test: {y_test.shape}\")\n",
    "\n",
    "# Análisis de distribución de clases en cada conjunto\n",
    "print(f\"\\n=== Distribución de Clases por Conjunto ===\")\n",
    "\n",
    "train_distribution = y_train.value_counts().sort_index()\n",
    "test_distribution = y_test.value_counts().sort_index()\n",
    "\n",
    "print(\"Conjunto de Entrenamiento:\")\n",
    "print(f\"  Clase 0 (normal): {train_distribution[0]} ({train_distribution[0]/len(y_train)*100:.2f}%)\")\n",
    "print(f\"  Clase 1 (pre-falla): {train_distribution[1]} ({train_distribution[1]/len(y_train)*100:.2f}%)\")\n",
    "print(f\"  Ratio de desbalance: {train_distribution[0]/train_distribution[1]:.1f}:1\")\n",
    "\n",
    "print(\"\\nConjunto de Prueba:\")\n",
    "print(f\"  Clase 0 (normal): {test_distribution[0]} ({test_distribution[0]/len(y_test)*100:.2f}%)\")\n",
    "print(f\"  Clase 1 (pre-falla): {test_distribution[1]} ({test_distribution[1]/len(y_test)*100:.2f}%)\")\n",
    "print(f\"  Ratio de desbalance: {test_distribution[0]/test_distribution[1]:.1f}:1\")\n",
    "\n",
    "# Visualización de la división cronológica\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Distribución temporal de la variable objetivo\n",
    "ax1.plot(range(len(y)), y.values, alpha=0.7, linewidth=0.8)\n",
    "ax1.axvline(x=split_index, color='red', linestyle='--', linewidth=2, label='Punto de División')\n",
    "ax1.set_title('División Cronológica del Dataset')\n",
    "ax1.set_xlabel('Índice Temporal')\n",
    "ax1.set_ylabel('Variable Objetivo (falla)')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Comparación de distribuciones de clases\n",
    "sets = ['Entrenamiento', 'Prueba']\n",
    "normal_counts = [train_distribution[0], test_distribution[0]]\n",
    "failure_counts = [train_distribution[1], test_distribution[1]]\n",
    "\n",
    "x = np.arange(len(sets))\n",
    "width = 0.35\n",
    "\n",
    "ax2.bar(x - width/2, normal_counts, width, label='Clase 0 (Normal)', alpha=0.8)\n",
    "ax2.bar(x + width/2, failure_counts, width, label='Clase 1 (Pre-falla)', alpha=0.8)\n",
    "ax2.set_title('Distribución de Clases por Conjunto')\n",
    "ax2.set_xlabel('Conjunto de Datos')\n",
    "ax2.set_ylabel('Número de Muestras')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(sets)\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nDivisión cronológica implementada correctamente\")\n",
    "print(\"El modelo será entrenado exclusivamente con datos históricos\")\n",
    "print(\"La evaluación se realizará sobre datos temporalmente posteriores\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
