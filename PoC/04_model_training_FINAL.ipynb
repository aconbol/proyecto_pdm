{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6gwsex11lxl",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialización del modelo final para despliegue\n",
    "\n",
    "print(\"=== Proceso de Serialización del Modelo Final ===\")\n",
    "\n",
    "# Verificación de la estructura del directorio de modelos\n",
    "print(f\"Directorio de destino: {models_path}\")\n",
    "print(f\"Directorio existe: {models_path.exists()}\")\n",
    "\n",
    "if not models_path.exists():\n",
    "    models_path.mkdir(parents=True, exist_ok=True)\n",
    "    print(\"Directorio de modelos creado exitosamente\")\n",
    "\n",
    "# Definición del nombre del archivo del modelo\n",
    "model_filename = 'modelo_mantenimiento_predictivo.joblib'\n",
    "model_path = models_path / model_filename\n",
    "\n",
    "print(f\"\\nGuardando modelo final: {best_model_name}\")\n",
    "print(f\"Ruta de destino: {model_path}\")\n",
    "\n",
    "try:\n",
    "    # Serialización del pipeline completo\n",
    "    joblib.dump(best_pipeline, model_path)\n",
    "    \n",
    "    # Verificación de la serialización\n",
    "    file_size = model_path.stat().st_size / 1024  # Tamaño en KB\n",
    "    print(f\"Modelo guardado exitosamente\")\n",
    "    print(f\"Tamaño del archivo: {file_size:.2f} KB\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error durante la serialización: {e}\")\n",
    "    raise\n",
    "\n",
    "# Creación de archivo de metadatos del modelo\n",
    "metadata = {\n",
    "    'modelo_seleccionado': best_model_name,\n",
    "    'fecha_entrenamiento': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'metricas_rendimiento': {\n",
    "        'auc_roc': float(detailed_metrics[best_model_name]['auc_roc']),\n",
    "        'f1_score': float(detailed_metrics[best_model_name]['f1_score']),\n",
    "        'precision_clase_pre_falla': float(detailed_metrics[best_model_name]['precision_class_1']),\n",
    "        'recall_clase_pre_falla': float(detailed_metrics[best_model_name]['recall_class_1']),\n",
    "        'tiempo_entrenamiento_segundos': float(detailed_metrics[best_model_name]['training_time'])\n",
    "    },\n",
    "    'datos_entrenamiento': {\n",
    "        'tamaño_conjunto_entrenamiento': int(len(X_train)),\n",
    "        'tamaño_conjunto_prueba': int(len(X_test)),\n",
    "        'numero_caracteristicas': int(X_train.shape[1]),\n",
    "        'distribucion_clases_entrenamiento': {\n",
    "            'clase_0_normal': int(y_train.value_counts()[0]),\n",
    "            'clase_1_pre_falla': int(y_train.value_counts()[1])\n",
    "        }\n",
    "    },\n",
    "    'configuracion_pipeline': {\n",
    "        'preprocesamiento': 'StandardScaler',\n",
    "        'algoritmo': best_model_name,\n",
    "        'parametros_modelo': str(best_pipeline.named_steps['classifier'].get_params())\n",
    "    }\n",
    "}\n",
    "\n",
    "# Guardar metadatos en formato JSON\n",
    "import json\n",
    "metadata_path = models_path / 'modelo_metadatos.json'\n",
    "\n",
    "with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(metadata, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nMetadatos del modelo guardados en: {metadata_path}\")\n",
    "\n",
    "# Verificación de carga del modelo (prueba de integridad)\n",
    "print(\"\\n=== Verificación de Integridad del Modelo Serializado ===\")\n",
    "\n",
    "try:\n",
    "    # Carga del modelo guardado\n",
    "    loaded_pipeline = joblib.load(model_path)\n",
    "    \n",
    "    # Verificación de estructura\n",
    "    print(f\"Pipeline cargado exitosamente\")\n",
    "    print(f\"Pasos del pipeline: {list(loaded_pipeline.named_steps.keys())}\")\n",
    "    \n",
    "    # Prueba de predicción con una muestra\n",
    "    if len(X_test) > 0:\n",
    "        sample_prediction = loaded_pipeline.predict(X_test.iloc[:1])\n",
    "        sample_probability = loaded_pipeline.predict_proba(X_test.iloc[:1])\n",
    "        \n",
    "        print(f\"Prueba de predicción exitosa:\")\n",
    "        print(f\"  Predicción: {sample_prediction[0]}\")\n",
    "        print(f\"  Probabilidades: {sample_probability[0]}\")\n",
    "    \n",
    "    # Verificación de equivalencia con el modelo original\n",
    "    original_predictions = best_pipeline.predict(X_test.iloc[:10])\n",
    "    loaded_predictions = loaded_pipeline.predict(X_test.iloc[:10])\n",
    "    \n",
    "    predictions_match = np.array_equal(original_predictions, loaded_predictions)\n",
    "    print(f\"  Equivalencia con modelo original: {predictions_match}\")\n",
    "    \n",
    "    if predictions_match:\n",
    "        print(\"✅ Verificación de integridad EXITOSA\")\n",
    "    else:\n",
    "        print(\"❌ Verificación de integridad FALLIDA\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error durante la verificación: {e}\")\n",
    "    raise\n",
    "\n",
    "print(f\"\\n=== Resumen del Modelo Final ===\")\n",
    "print(f\"Modelo serializado: {best_model_name}\")\n",
    "print(f\"Archivo del modelo: {model_filename}\")\n",
    "print(f\"Tamaño del archivo: {file_size:.2f} KB\")\n",
    "print(f\"Rendimiento (AUC-ROC): {detailed_metrics[best_model_name]['auc_roc']:.4f}\")\n",
    "print(f\"Rendimiento (F1-Score): {detailed_metrics[best_model_name]['f1_score']:.4f}\")\n",
    "print(f\"Recall clase pre-falla: {detailed_metrics[best_model_name]['recall_class_1']:.4f}\")\n",
    "print(\"\\n✅ Proceso de entrenamiento y serialización completado exitosamente\")\n",
    "print(\"\\nEl modelo está listo para ser utilizado en la fase de evaluación (Notebook 05)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "o1z685dd2mt",
   "metadata": {},
   "source": [
    "## Paso 7: Guardado del Modelo Final (Serialización)\n",
    "\n",
    "### Importancia de la Serialización del Pipeline Completo\n",
    "\n",
    "La serialización del modelo entrenado constituye un paso crítico en el flujo de trabajo de machine learning, especialmente para aplicaciones de mantenimiento predictivo que requieren despliegue en entornos operacionales. El enfoque implementado guarda el pipeline completo, no únicamente el algoritmo de clasificación, por las siguientes razones técnicas:\n",
    "\n",
    "#### Ventajas de Guardar el Pipeline Completo:\n",
    "\n",
    "1. **Consistencia de Preprocesamiento**: El pipeline encapsula tanto el StandardScaler como el clasificador, garantizando que las nuevas muestras reciban exactamente las mismas transformaciones aplicadas durante el entrenamiento.\n",
    "\n",
    "2. **Eliminación de Discrepancias**: Previene errores de implementación que podrían surgir al aplicar manualmente las transformaciones de normalización en el entorno de producción.\n",
    "\n",
    "3. **Portabilidad**: El pipeline serializado contiene toda la información necesaria para realizar predicciones, incluyendo los parámetros de normalización calculados sobre el conjunto de entrenamiento.\n",
    "\n",
    "4. **Versionado**: Facilita el control de versiones del modelo completo, incluyendo tanto el preprocesamiento como los parámetros del algoritmo.\n",
    "\n",
    "### Formato de Serialización\n",
    "\n",
    "Se utiliza joblib para la serialización, que ofrece mayor eficiencia que pickle para objetos NumPy y scikit-learn, especialmente importante en modelos con gran cantidad de parámetros como Random Forest.\n",
    "\n",
    "### Uso Futuro del Modelo Serializado\n",
    "\n",
    "El pipeline guardado podrá ser cargado en futuros notebooks de evaluación o en sistemas de producción para realizar predicciones en tiempo real sobre nuevos datos operacionales del moto-compresor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28tpgi8m89w",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de importancia de características para el modelo seleccionado\n",
    "\n",
    "print(f\"=== Análisis de Interpretabilidad - {best_model_name} ===\")\n",
    "\n",
    "# Verificación de capacidad de análisis de importancia\n",
    "classifier = best_pipeline.named_steps['classifier']\n",
    "\n",
    "if hasattr(classifier, 'feature_importances_'):\n",
    "    print(f\"Analizando importancia de características para {best_model_name}...\")\n",
    "    \n",
    "    # Extracción de importancias de características\n",
    "    feature_importances = classifier.feature_importances_\n",
    "    feature_names = X_train.columns\n",
    "    \n",
    "    # Creación de DataFrame con importancias\n",
    "    importance_df = pd.DataFrame({\n",
    "        'caracteristica': feature_names,\n",
    "        'importancia': feature_importances\n",
    "    }).sort_values('importancia', ascending=False)\n",
    "    \n",
    "    # Estadísticas de importancia\n",
    "    print(f\"\\\\nEstadísticas de importancia de características:\")\n",
    "    print(f\"Total de características: {len(feature_importances)}\")\n",
    "    print(f\"Importancia máxima: {feature_importances.max():.6f}\")\n",
    "    print(f\"Importancia mínima: {feature_importances.min():.6f}\")\n",
    "    print(f\"Importancia media: {feature_importances.mean():.6f}\")\n",
    "    \n",
    "    # Análisis de concentración de importancia\n",
    "    top_20_importance = importance_df.head(20)['importancia'].sum()\n",
    "    total_importance = importance_df['importancia'].sum()\n",
    "    concentration_ratio = top_20_importance / total_importance\n",
    "    \n",
    "    print(f\"Concentración de importancia en top 20 características: {concentration_ratio:.2%}\")\n",
    "    \n",
    "    # Visualización de las características más importantes\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Top 20 características más importantes\n",
    "    top_features = importance_df.head(20)\n",
    "    \n",
    "    # Gráfico de barras horizontales\n",
    "    bars = plt.barh(range(len(top_features)), top_features['importancia'], \n",
    "                    color=plt.cm.viridis(np.linspace(0, 1, len(top_features))))\n",
    "    \n",
    "    # Configuración del gráfico\n",
    "    plt.yticks(range(len(top_features)), top_features['caracteristica'])\n",
    "    plt.xlabel('Importancia de Característica')\n",
    "    plt.title(f'Top 20 Características Más Importantes - {best_model_name}', \n",
    "              fontsize=14, fontweight='bold')\n",
    "    plt.gca().invert_yaxis()  # Invertir para mostrar la más importante arriba\n",
    "    \n",
    "    # Añadir valores de importancia en las barras\n",
    "    for i, (bar, importance) in enumerate(zip(bars, top_features['importancia'])):\n",
    "        plt.text(bar.get_width() + 0.0001, bar.get_y() + bar.get_height()/2, \n",
    "                 f'{importance:.4f}', ha='left', va='center', fontsize=8)\n",
    "    \n",
    "    plt.grid(True, alpha=0.3, axis='x')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Tabla detallada de características más importantes\n",
    "    print(f\"\\\\n=== Top 15 Características Más Importantes ===\\\")\n",
    "    top_15 = importance_df.head(15).copy()\n",
    "    top_15['importancia_porcentual'] = (top_15['importancia'] / total_importance * 100).round(2)\n",
    "    top_15.index = range(1, len(top_15) + 1)\n",
    "    \n",
    "    print(top_15[['caracteristica', 'importancia', 'importancia_porcentual']].to_string())\n",
    "    \n",
    "    # Análisis de tipos de características importantes\n",
    "    print(f\"\\\\n=== Análisis de Tipos de Características Importantes ===\\\")\n",
    "    \n",
    "    # Categorización de características por tipo\n",
    "    feature_types = {\n",
    "        'moving_avg': 0, 'lag': 0, 'rolling': 0, 'shift': 0, \n",
    "        'std': 0, 'min': 0, 'max': 0, 'mean': 0, 'original': 0\n",
    "    }\n",
    "    \n",
    "    for feature in top_15['caracteristica']:\n",
    "        feature_lower = feature.lower()\n",
    "        categorized = False\n",
    "        \n",
    "        for feature_type in feature_types.keys():\n",
    "            if feature_type in feature_lower:\n",
    "                feature_types[feature_type] += 1\n",
    "                categorized = True\n",
    "                break\n",
    "        \n",
    "        if not categorized:\n",
    "            feature_types['original'] += 1\n",
    "    \n",
    "    # Mostrar distribución de tipos\n",
    "    print(\"Distribución de tipos de características en Top 15:\")\n",
    "    for feature_type, count in feature_types.items():\n",
    "        if count > 0:\n",
    "            print(f\"  {feature_type.replace('_', ' ').title()}: {count} características\")\n",
    "\n",
    "elif hasattr(classifier, 'coef_'):\n",
    "    print(f\"Analizando coeficientes para {best_model_name}...\")\n",
    "    \n",
    "    # Para modelos lineales, usar valores absolutos de coeficientes\n",
    "    coefficients = np.abs(classifier.coef_[0])\n",
    "    feature_names = X_train.columns\n",
    "    \n",
    "    # Creación de DataFrame con coeficientes\n",
    "    importance_df = pd.DataFrame({\n",
    "        'caracteristica': feature_names,\n",
    "        'coeficiente_abs': coefficients\n",
    "    }).sort_values('coeficiente_abs', ascending=False)\n",
    "    \n",
    "    print(f\"\\\\n=== Top 15 Características por Magnitud de Coeficiente ===\\\")\n",
    "    print(importance_df.head(15).to_string(index=False))\n",
    "    \n",
    "    # Visualización similar para modelos lineales\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_features = importance_df.head(20)\n",
    "    \n",
    "    plt.barh(range(len(top_features)), top_features['coeficiente_abs'])\n",
    "    plt.yticks(range(len(top_features)), top_features['caracteristica'])\n",
    "    plt.xlabel('Magnitud del Coeficiente (Valor Absoluto)')\n",
    "    plt.title(f'Top 20 Características por Coeficiente - {best_model_name}', \n",
    "              fontsize=14, fontweight='bold')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.grid(True, alpha=0.3, axis='x')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(f\"El modelo {best_model_name} no proporciona medidas de importancia de características interpretables.\")\n",
    "    print(\"Se recomienda utilizar métodos de interpretabilidad externos como SHAP para análisis detallado.\")\n",
    "\n",
    "print(f\"\\\\nAnálisis de interpretabilidad completado para {best_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qbvymjqgq6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selección del mejor modelo basada en criterios múltiples\n",
    "\n",
    "print(\"=== Proceso de Selección del Modelo Óptimo ===\")\n",
    "\n",
    "# Cálculo de métricas detalladas para cada modelo\n",
    "detailed_metrics = {}\n",
    "model_names = list(results.keys())\n",
    "\n",
    "for model_name in model_names:\n",
    "    y_pred = results[model_name]['predictions']\n",
    "    \n",
    "    # Cálculo del reporte de clasificación en formato de diccionario\n",
    "    class_report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "    \n",
    "    detailed_metrics[model_name] = {\n",
    "        'auc_roc': results[model_name]['auc_roc'],\n",
    "        'f1_score': results[model_name]['f1_score'],\n",
    "        'precision_class_1': class_report['1']['precision'],\n",
    "        'recall_class_1': class_report['1']['recall'],\n",
    "        'training_time': results[model_name]['training_time']\n",
    "    }\n",
    "\n",
    "# Creación de DataFrame para análisis comparativo\n",
    "metrics_df = pd.DataFrame(detailed_metrics).T\n",
    "metrics_df = metrics_df.round(4)\n",
    "\n",
    "print(\"Métricas detalladas por modelo:\")\n",
    "print(metrics_df)\n",
    "\n",
    "# Implementación de sistema de puntuación ponderada para selección\n",
    "print(\"\\n=== Sistema de Puntuación para Selección de Modelo ===\")\n",
    "\n",
    "# Pesos asignados a cada métrica (ajustables según prioridades operacionales)\n",
    "weights = {\n",
    "    'auc_roc': 0.25,           # Capacidad general de discriminación\n",
    "    'f1_score': 0.30,          # Balance precision-recall\n",
    "    'recall_class_1': 0.35,    # Crítico: detección de pre-fallas\n",
    "    'training_efficiency': 0.10 # Eficiencia computacional\n",
    "}\n",
    "\n",
    "print(f\"Pesos asignados: {weights}\")\n",
    "\n",
    "# Normalización de métricas y cálculo de puntuación\n",
    "scores = {}\n",
    "max_training_time = max([detailed_metrics[name]['training_time'] for name in model_names])\n",
    "\n",
    "for model_name in model_names:\n",
    "    metrics = detailed_metrics[model_name]\n",
    "    \n",
    "    # Normalización de eficiencia computacional (invertida: menor tiempo = mejor)\n",
    "    training_efficiency = 1 - (metrics['training_time'] / max_training_time)\n",
    "    \n",
    "    # Cálculo de puntuación ponderada\n",
    "    score = (\n",
    "        weights['auc_roc'] * metrics['auc_roc'] +\n",
    "        weights['f1_score'] * metrics['f1_score'] +\n",
    "        weights['recall_class_1'] * metrics['recall_class_1'] +\n",
    "        weights['training_efficiency'] * training_efficiency\n",
    "    )\n",
    "    \n",
    "    scores[model_name] = {\n",
    "        'puntuacion_total': score,\n",
    "        'training_efficiency': training_efficiency\n",
    "    }\n",
    "\n",
    "# Identificación del mejor modelo\n",
    "best_model_name = max(scores.keys(), key=lambda x: scores[x]['puntuacion_total'])\n",
    "best_pipeline = trained_pipelines[best_model_name]\n",
    "\n",
    "print(f\"\\n=== Resultado de la Selección ===\")\n",
    "print(f\"Modelo seleccionado: {best_model_name}\")\n",
    "print(f\"Puntuación total: {scores[best_model_name]['puntuacion_total']:.4f}\")\n",
    "\n",
    "# Resumen de rendimiento del modelo seleccionado\n",
    "best_metrics = detailed_metrics[best_model_name]\n",
    "print(f\"\\nRendimiento del modelo seleccionado:\")\n",
    "print(f\"  AUC-ROC: {best_metrics['auc_roc']:.4f}\")\n",
    "print(f\"  F1-Score: {best_metrics['f1_score']:.4f}\")\n",
    "print(f\"  Precision Clase Pre-Falla: {best_metrics['precision_class_1']:.4f}\")\n",
    "print(f\"  Recall Clase Pre-Falla: {best_metrics['recall_class_1']:.4f}\")\n",
    "print(f\"  Tiempo de Entrenamiento: {best_metrics['training_time']:.2f} segundos\")\n",
    "\n",
    "# Justificación de la selección\n",
    "print(f\"\\n=== Justificación de la Selección ===\")\n",
    "print(f\"El modelo {best_model_name} fue seleccionado basándose en:\")\n",
    "print(f\"1. Alto recall para clase pre-falla: {best_metrics['recall_class_1']:.4f} (crítico para detectar fallas)\")\n",
    "print(f\"2. F1-score balanceado: {best_metrics['f1_score']:.4f} (equilibrio precision-recall)\")\n",
    "print(f\"3. Capacidad de discriminación: AUC-ROC {best_metrics['auc_roc']:.4f}\")\n",
    "print(f\"4. Eficiencia computacional aceptable: {best_metrics['training_time']:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "omdp8swbao",
   "metadata": {},
   "source": [
    "## Paso 6: Selección del Mejor Modelo y Análisis de Importancia\n",
    "\n",
    "### Criterios de Selección del Modelo Óptimo\n",
    "\n",
    "La selección del modelo óptimo para aplicaciones de mantenimiento predictivo requiere un análisis multidimensional que considere tanto el rendimiento predictivo como las restricciones operacionales. Los criterios de evaluación implementados priorizan:\n",
    "\n",
    "#### Métricas Críticas para Mantenimiento Predictivo:\n",
    "\n",
    "1. **Recall (Sensibilidad) para Clase Pre-Falla**: Capacidad del modelo para detectar correctamente las situaciones de pre-falla. En mantenimiento predictivo, los falsos negativos (fallas no detectadas) tienen consecuencias operacionales críticas.\n",
    "\n",
    "2. **F1-Score**: Métrica que equilibra precisión y recall, especialmente relevante en contextos de desbalance de clases donde ambas métricas son importantes.\n",
    "\n",
    "3. **AUC-ROC**: Capacidad general de discriminación entre clases, independiente del umbral de clasificación.\n",
    "\n",
    "4. **Eficiencia Computacional**: Tiempo de entrenamiento y complejidad del modelo, factores determinantes para la implementación operacional.\n",
    "\n",
    "### Justificación de la Selección\n",
    "\n",
    "La selección se basa en una evaluación integral que prioriza el recall para la clase pre-falla sobre otras métricas, dado que el costo de no detectar una falla inminente es significativamente mayor que el de una falsa alarma en aplicaciones de mantenimiento industrial.\n",
    "\n",
    "### Interpretabilidad del Modelo Seleccionado\n",
    "\n",
    "En aplicaciones industriales críticas, la interpretabilidad del modelo es fundamental para:\n",
    "- Validación por expertos en mantenimiento\n",
    "- Identificación de sensores y variables críticas\n",
    "- Optimización de estrategias de monitoreo\n",
    "- Cumplimiento de requisitos regulatorios\n",
    "\n",
    "Para modelos de tipo Random Forest, el análisis de importancia de características proporciona insights valiosos sobre qué variables operacionales son más predictivas de fallas inminentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ib29g93egk",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de algoritmos de clasificación para evaluación\n",
    "\n",
    "print(\"=== Configuración de Algoritmos de Clasificación ===\")\n",
    "\n",
    "# Diccionario de modelos con configuraciones optimizadas para desbalance de clases\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(\n",
    "        class_weight='balanced',  # Manejo automático de desbalance\n",
    "        random_state=42,          # Reproducibilidad\n",
    "        max_iter=1000,           # Suficientes iteraciones para convergencia\n",
    "        solver='liblinear'        # Solver eficiente para datasets moderados\n",
    "    ),\n",
    "    \n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        class_weight='balanced',  # Manejo automático de desbalance\n",
    "        random_state=42,          # Reproducibilidad\n",
    "        n_estimators=100,         # Balance entre rendimiento y velocidad\n",
    "        max_depth=10,            # Prevención de overfitting\n",
    "        min_samples_split=5,      # Criterio conservador para divisiones\n",
    "        min_samples_leaf=2        # Hojas con múltiples muestras\n",
    "    )\n",
    "}\n",
    "\n",
    "print(f\"Algoritmos configurados: {list(models.keys())}\")\n",
    "print(f\"Todos los modelos incluyen manejo de desbalance de clases\")\n",
    "\n",
    "# Contenedor para almacenar resultados de evaluación\n",
    "results = {}\n",
    "trained_pipelines = {}\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"INICIO DEL PROCESO DE ENTRENAMIENTO Y EVALUACIÓN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Iteración a través de cada algoritmo\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n{'='*20} {model_name} {'='*20}\")\n",
    "    \n",
    "    # Creación del pipeline específico para este modelo\n",
    "    pipeline = create_pipeline(model)\n",
    "    \n",
    "    print(f\"Entrenando {model_name}...\")\n",
    "    \n",
    "    # Entrenamiento del pipeline\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"Tiempo de entrenamiento: {training_time:.2f} segundos\")\n",
    "    \n",
    "    # Predicciones sobre conjunto de prueba\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_pred_proba = pipeline.predict_proba(X_test)[:, 1]  # Probabilidades clase positiva\n",
    "    \n",
    "    # Cálculo de métricas de evaluación\n",
    "    auc_roc = roc_auc_score(y_test, y_pred_proba)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Almacenamiento de resultados\n",
    "    results[model_name] = {\n",
    "        'predictions': y_pred,\n",
    "        'probabilities': y_pred_proba,\n",
    "        'auc_roc': auc_roc,\n",
    "        'f1_score': f1,\n",
    "        'training_time': training_time\n",
    "    }\n",
    "    trained_pipelines[model_name] = pipeline\n",
    "    \n",
    "    print(f\"AUC-ROC: {auc_roc:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    \n",
    "    # Matriz de confusión visualizada\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Normal', 'Pre-falla'],\n",
    "                yticklabels=['Normal', 'Pre-falla'])\n",
    "    plt.title(f'Matriz de Confusión - {model_name}')\n",
    "    plt.ylabel('Valor Real')\n",
    "    plt.xlabel('Predicción')\n",
    "    plt.show()\n",
    "    \n",
    "    # Reporte de clasificación detallado\n",
    "    print(f\"\\n--- Reporte de Clasificación - {model_name} ---\")\n",
    "    print(classification_report(y_test, y_pred, \n",
    "                              target_names=['Normal', 'Pre-falla'],\n",
    "                              digits=4))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ENTRENAMIENTO Y EVALUACIÓN COMPLETADOS\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "n6qqa7vl3ji",
   "metadata": {},
   "source": [
    "## Paso 5: Entrenamiento y Evaluación de Modelos Base\n",
    "\n",
    "### Estrategia de Selección de Algoritmos\n",
    "\n",
    "Para establecer una línea base sólida de rendimiento, se implementarán múltiples algoritmos de clasificación que cubren diferentes aproximaciones metodológicas al problema de predicción de fallas. La selección de algoritmos se basa en:\n",
    "\n",
    "#### Algoritmos Implementados:\n",
    "\n",
    "1. **Regresión Logística**: \n",
    "   - Modelo lineal interpretable y computacionalmente eficiente\n",
    "   - Proporciona probabilidades calibradas de clasificación\n",
    "   - Establece una línea base sólida para comparación\n",
    "\n",
    "2. **Random Forest Classifier**:\n",
    "   - Ensemble de árboles de decisión con alta capacidad predictiva\n",
    "   - Robusto ante overfitting y capaz de capturar interacciones complejas\n",
    "   - Proporciona medidas de importancia de características\n",
    "\n",
    "### Manejo del Desbalance de Clases\n",
    "\n",
    "Dado el desbalance inherente en datos de mantenimiento predictivo, todos los algoritmos implementarán `class_weight='balanced'`. Esta configuración ajusta automáticamente los pesos de las clases de forma inversamente proporcional a su frecuencia, mejorando la capacidad del modelo para detectar la clase minoritaria (pre-falla).\n",
    "\n",
    "### Métricas de Evaluación para Clasificación Desbalanceada\n",
    "\n",
    "La evaluación se realizará utilizando métricas específicamente apropiadas para problemas de clasificación desbalanceada:\n",
    "\n",
    "- **Matriz de Confusión**: Análisis detallado de verdaderos/falsos positivos y negativos\n",
    "- **Precision, Recall y F1-Score**: Especialmente críticos para la clase minoritaria\n",
    "- **AUC-ROC**: Capacidad de discriminación entre clases\n",
    "- **Curva Precision-Recall**: Más informativa que ROC en casos de desbalance extremo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "autud3l8b1n",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación del pipeline de modelado\n",
    "\n",
    "print(\"=== Configuración del Pipeline de Modelado ===\")\n",
    "\n",
    "# Definición de la estructura base del pipeline\n",
    "# El pipeline incluye dos etapas principales:\n",
    "# 1. Preprocesamiento: StandardScaler para normalización de características\n",
    "# 2. Clasificador: Será intercambiable según el algoritmo a evaluar\n",
    "\n",
    "def create_pipeline(classifier):\n",
    "    \"\"\"\n",
    "    Crea un pipeline de machine learning con preprocesamiento y clasificación.\n",
    "    \n",
    "    Args:\n",
    "        classifier: Algoritmo de clasificación de scikit-learn\n",
    "        \n",
    "    Returns:\n",
    "        Pipeline configurado con StandardScaler y el clasificador especificado\n",
    "    \"\"\"\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),  # Normalización de características\n",
    "        ('classifier', classifier)      # Algoritmo de clasificación\n",
    "    ])\n",
    "    return pipeline\n",
    "\n",
    "# Verificación de la estructura de características\n",
    "print(f\"Número de características de entrada: {X_train.shape[1]}\")\n",
    "print(f\"Tipos de datos en características:\")\n",
    "print(X_train.dtypes.value_counts())\n",
    "\n",
    "# Análisis estadístico básico de las características\n",
    "print(f\"\\n=== Estadísticos de las Características (Conjunto de Entrenamiento) ===\")\n",
    "stats_summary = X_train.describe()\n",
    "print(f\"Rango de medias: {stats_summary.loc['mean'].min():.4f} a {stats_summary.loc['mean'].max():.4f}\")\n",
    "print(f\"Rango de desviaciones estándar: {stats_summary.loc['std'].min():.4f} a {stats_summary.loc['std'].max():.4f}\")\n",
    "print(f\"Rango de valores mínimos: {stats_summary.loc['min'].min():.4f} a {stats_summary.loc['min'].max():.4f}\")\n",
    "print(f\"Rango de valores máximos: {stats_summary.loc['max'].min():.4f} a {stats_summary.loc['max'].max():.4f}\")\n",
    "\n",
    "# Demostración de la necesidad de normalización\n",
    "scales_differ = (stats_summary.loc['std'].max() / stats_summary.loc['std'].min()) > 10\n",
    "print(f\"\\n¿Las características tienen escalas significativamente diferentes? {scales_differ}\")\n",
    "print(f\"Ratio de escala máxima/mínima: {stats_summary.loc['std'].max() / stats_summary.loc['std'].min():.1f}\")\n",
    "\n",
    "if scales_differ:\n",
    "    print(\"La normalización es necesaria debido a las diferencias de escala entre características\")\n",
    "else:\n",
    "    print(\"Las características tienen escalas similares, pero la normalización sigue siendo recomendable\")\n",
    "\n",
    "print(\"\\nPipeline de modelado configurado exitosamente\")\n",
    "print(\"Estructura: StandardScaler → Clasificador\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fynbngl54q",
   "metadata": {},
   "source": [
    "## Paso 4: Creación del Pipeline de Modelado\n",
    "\n",
    "### Arquitectura de Pipeline para Machine Learning\n",
    "\n",
    "La implementación de un Pipeline de scikit-learn proporciona una arquitectura robusta y escalable para el proceso de modelado, encapsulando tanto el preprocesamiento como el algoritmo de clasificación en una unidad cohesiva. Esta aproximación ofrece múltiples ventajas operacionales:\n",
    "\n",
    "#### Beneficios del Pipeline:\n",
    "\n",
    "1. **Consistencia en el Preprocesamiento**: Garantiza que las mismas transformaciones aplicadas durante el entrenamiento se apliquen automáticamente durante la inferencia, eliminando discrepancias que podrían degradar el rendimiento del modelo.\n",
    "\n",
    "2. **Prevención de Data Leakage**: El pipeline asegura que las estadísticas de normalización (media, desviación estándar) se calculen exclusivamente sobre el conjunto de entrenamiento y se apliquen posteriormente al conjunto de prueba.\n",
    "\n",
    "3. **Reproducibilidad**: Encapsula todo el proceso de transformación y modelado en un objeto serializable, facilitando la reproducibilidad y el despliegue.\n",
    "\n",
    "4. **Mantenibilidad**: Simplifica el código y reduce la posibilidad de errores al manejar múltiples pasos de procesamiento.\n",
    "\n",
    "### Componentes del Pipeline:\n",
    "\n",
    "1. **StandardScaler**: Normaliza las características para que tengan media cero y desviación estándar uno, requisito fundamental para algoritmos sensibles a la escala como la Regresión Logística.\n",
    "\n",
    "2. **Clasificador**: Algoritmo de machine learning que será intercambiable para permitir la comparación de diferentes enfoques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Fase 4: Entrenamiento y Selección de Modelos de Clasificación\n",
    "\n",
    "## Objetivo del Notebook\n",
    "\n",
    "Este notebook constituye la cuarta fase del pipeline de mantenimiento predictivo para sistemas de moto-compresores. El objetivo principal es entrenar, evaluar y seleccionar un modelo de clasificación binaria capaz de predecir si ocurrirá una falla en los próximos 7 días, utilizando las características derivadas del proceso de ingeniería de características implementado en la fase anterior.\n",
    "\n",
    "### Metodología de Entrenamiento\n",
    "\n",
    "La metodología implementada se basa en principios fundamentales de machine learning para series temporales, priorizando:\n",
    "\n",
    "1. **División Cronológica de Datos**: Implementación de una división temporal que respete la naturaleza secuencial de los datos operacionales, evitando la fuga de información (data leakage) que comprometería la validez del modelo.\n",
    "\n",
    "2. **Manejo de Desbalance de Clases**: Aplicación de técnicas específicas para abordar la distribución desigual entre muestras de operación normal y muestras pre-falla, fundamental en aplicaciones de mantenimiento predictivo.\n",
    "\n",
    "3. **Evaluación Robusta**: Utilización de métricas de rendimiento apropiadas para clasificación desbalanceada, que proporcionen una evaluación objetiva de la capacidad predictiva del modelo.\n",
    "\n",
    "4. **Simplicidad Computacional**: Selección de algoritmos que mantengan un balance óptimo entre rendimiento predictivo y eficiencia computacional.\n",
    "\n",
    "### Variable Objetivo Creada\n",
    "\n",
    "La variable objetivo 'falla' ha sido creada basándose en el historial real de eventos de falla del compresor, donde:\n",
    "- **Clase 0 (Normal)**: Operación normal del equipo\n",
    "- **Clase 1 (Pre-falla)**: Muestras dentro de la ventana de 7 días previa a una falla documentada\n",
    "\n",
    "### Librerías y Dependencias\n",
    "\n",
    "El desarrollo requiere las siguientes librerías especializadas:\n",
    "- **pandas, numpy**: Manipulación y procesamiento de datos\n",
    "- **pathlib**: Gestión de rutas del sistema de archivos\n",
    "- **joblib**: Serialización eficiente de modelos\n",
    "- **matplotlib, seaborn**: Visualización de resultados y métricas\n",
    "- **sklearn**: Algoritmos de machine learning, pipelines y métricas de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías fundamentales para manipulación de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Librerías para visualización de resultados\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuración de estilo para visualizaciones\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Importación de algoritmos de machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Importación de herramientas de pipeline y preprocesamiento\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Importación de métricas de evaluación para clasificación\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    roc_auc_score, \n",
    "    precision_recall_curve,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "# Definición de rutas del proyecto\n",
    "data_processed_path = Path('./data/processed')\n",
    "models_path = Path('./data/models')\n",
    "\n",
    "# Creación de directorio de modelos si no existe\n",
    "models_path.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Configuración del entorno completada exitosamente\")\n",
    "print(f\"Directorio de datos procesados: {data_processed_path}\")\n",
    "print(f\"Directorio de modelos: {models_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Paso 2: Carga y Preparación de Datos\n",
    "\n",
    "### Proceso de Carga de Dataset\n",
    "\n",
    "En esta etapa se procede a cargar el dataset resultante del proceso de ingeniería de características desarrollado en la fase anterior, ahora enriquecido con la variable objetivo 'falla' creada a partir del historial real de eventos de mantenimiento. El archivo `featured_dataset_with_target.parquet` contiene:\n",
    "\n",
    "- **Características originales de sensores**: Variables operacionales directas del moto-compresor\n",
    "- **Características de ventanas móviles**: Estadísticos calculados sobre períodos temporales específicos\n",
    "- **Características de lag temporal**: Variables retardadas que capturan dependencias temporales\n",
    "- **Variable objetivo**: Indicador binario de proximidad a falla basado en eventos reales documentados\n",
    "\n",
    "### Creación de la Variable Objetivo\n",
    "\n",
    "La variable objetivo ha sido construida utilizando el historial de eventos de falla documentados en el archivo 'Historial C1 RGD.xlsx'. El proceso implementado:\n",
    "\n",
    "1. **Extracción de Fechas**: Se procesaron automáticamente todas las fechas de eventos del historial\n",
    "2. **Ventana de Pre-falla**: Se definió una ventana de 7 días previos a cada evento como período crítico\n",
    "3. **Etiquetado**: Las muestras dentro de estas ventanas se etiquetaron como 'pre-falla' (1), el resto como 'normal' (0)\n",
    "\n",
    "### Separación de Características y Variable Objetivo\n",
    "\n",
    "La preparación de datos requiere la separación clara entre la matriz de características (X) y el vector de variable objetivo (y) para el entrenamiento supervisado del modelo de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga del dataset con características de ingeniería y variable objetivo\n",
    "dataset_path = data_processed_path / 'featured_dataset_with_target.parquet'\n",
    "\n",
    "try:\n",
    "    df = pd.read_parquet(dataset_path)\n",
    "    print(f\"Dataset cargado exitosamente desde: {dataset_path}\")\n",
    "    print(f\"Dimensiones del dataset: {df.shape}\")\n",
    "    print(f\"Memoria utilizada: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: No se encontró el archivo {dataset_path}\")\n",
    "    print(\"Ejecutando creación de variable objetivo...\")\n",
    "    \n",
    "    # Ejecutar script para crear variable objetivo\n",
    "    import subprocess\n",
    "    result = subprocess.run(['python', 'crear_variable_objetivo.py'], \n",
    "                          capture_output=True, text=True, cwd='.')\n",
    "    print(result.stdout)\n",
    "    if result.stderr:\n",
    "        print(f\"Errores: {result.stderr}\")\n",
    "    \n",
    "    # Intentar cargar nuevamente\n",
    "    df = pd.read_parquet(dataset_path)\n",
    "    print(f\"Dataset cargado exitosamente tras creación: {df.shape}\")\n",
    "\n",
    "# Verificación de la estructura del dataset\n",
    "print(\"\\n=== Información General del Dataset ===\")\n",
    "print(df.info())\n",
    "\n",
    "# Análisis de la variable objetivo\n",
    "print(\"\\n=== Distribución de la Variable Objetivo 'falla' ===\")\n",
    "target_distribution = df['falla'].value_counts().sort_index()\n",
    "print(target_distribution)\n",
    "print(f\"\\nPorcentaje de muestras normales (0): {(target_distribution[0] / len(df) * 100):.2f}%\")\n",
    "print(f\"Porcentaje de muestras pre-falla (1): {(target_distribution[1] / len(df) * 100):.2f}%\")\n",
    "print(f\"Ratio de desbalance: {target_distribution[0] / target_distribution[1]:.1f}:1\")\n",
    "\n",
    "# Separación de características y variable objetivo\n",
    "print(\"\\n=== Preparación de Matrices de Entrenamiento ===\")\n",
    "\n",
    "# Definición de la matriz de características (X)\n",
    "# Excluimos la columna 'falla' ya que es nuestra variable objetivo\n",
    "feature_columns = [col for col in df.columns if col != 'falla']\n",
    "X = df[feature_columns].copy()\n",
    "\n",
    "# Definición del vector objetivo (y)\n",
    "y = df['falla'].copy()\n",
    "\n",
    "print(f\"Matriz de características (X): {X.shape}\")\n",
    "print(f\"Vector objetivo (y): {y.shape}\")\n",
    "print(f\"Número de características disponibles: {len(feature_columns)}\")\n",
    "\n",
    "# Verificación de valores faltantes en características\n",
    "missing_values = X.isnull().sum().sum()\n",
    "print(f\"Valores faltantes en características: {missing_values}\")\n",
    "\n",
    "if missing_values > 0:\n",
    "    print(\"\\nCaracterísticas con valores faltantes:\")\n",
    "    missing_by_column = X.isnull().sum()\n",
    "    print(missing_by_column[missing_by_column > 0])\n",
    "\n",
    "# Análisis de la distribución temporal de fallas\n",
    "print(f\"\\n=== Análisis Temporal de la Variable Objetivo ===\")\n",
    "if isinstance(df.index, pd.DatetimeIndex):\n",
    "    # Distribución por año\n",
    "    df_temp = df.copy()\n",
    "    df_temp['año'] = df_temp.index.year\n",
    "    fallas_por_año = df_temp.groupby('año')['falla'].agg(['sum', 'count', 'mean'])\n",
    "    fallas_por_año.columns = ['fallas', 'total_muestras', 'proporcion_fallas']\n",
    "    print(\"Distribución de fallas por año:\")\n",
    "    print(fallas_por_año)\n",
    "else:\n",
    "    print(\"Dataset sin índice temporal - análisis temporal limitado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Paso 3: División Cronológica de Datos (Time-Based Split)\n",
    "\n",
    "### Importancia Crítica de la División Temporal\n",
    "\n",
    "La división de datos en series temporales requiere un enfoque metodológicamente diferente al utilizado en problemas de clasificación estándar. La función `train_test_split` de scikit-learn con `shuffle=True` es **fundamentalmente incorrecta** para datos de series temporales por las siguientes razones:\n",
    "\n",
    "#### Problemas de la División Aleatoria:\n",
    "\n",
    "1. **Fuga de Información (Data Leakage)**: Una división aleatoria permite que el modelo acceda a información futura durante el entrenamiento, creando una ventaja artificial que no existiría en un escenario de predicción real.\n",
    "\n",
    "2. **Validación No Realista**: En aplicaciones industriales de mantenimiento predictivo, el modelo debe predecir eventos futuros basándose únicamente en datos históricos. Una división aleatoria no simula esta condición operacional.\n",
    "\n",
    "3. **Sobreestimación del Rendimiento**: Los resultados obtenidos con división aleatoria tienden a sobrestimar significativamente la capacidad predictiva real del modelo.\n",
    "\n",
    "#### Metodología de División Cronológica:\n",
    "\n",
    "La división cronológica implementada respeta la naturaleza secuencial de los datos operacionales, utilizando un punto de corte temporal que separa:\n",
    "\n",
    "- **Conjunto de Entrenamiento**: Datos históricos (80% inicial del dataset)\n",
    "- **Conjunto de Prueba**: Datos más recientes (20% final del dataset)\n",
    "\n",
    "Esta metodología simula fielmente el escenario operacional donde el modelo predice fallas futuras basándose únicamente en el historial de operación disponible hasta el momento de la predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementación de división cronológica de datos\n",
    "\n",
    "print(\"=== Implementación de División Cronológica ===\")\n",
    "\n",
    "# Definición del punto de corte temporal (80% para entrenamiento)\n",
    "train_size = 0.8\n",
    "split_index = int(len(df) * train_size)\n",
    "\n",
    "print(f\"Tamaño total del dataset: {len(df)} muestras\")\n",
    "print(f\"Punto de corte temporal: índice {split_index}\")\n",
    "print(f\"Proporción de entrenamiento: {train_size*100}%\")\n",
    "print(f\"Proporción de prueba: {(1-train_size)*100}%\")\n",
    "\n",
    "# División cronológica de características\n",
    "X_train = X.iloc[:split_index].copy()\n",
    "X_test = X.iloc[split_index:].copy()\n",
    "\n",
    "# División cronológica de variable objetivo\n",
    "y_train = y.iloc[:split_index].copy()\n",
    "y_test = y.iloc[split_index:].copy()\n",
    "\n",
    "print(f\"\\n=== Dimensiones de los Conjuntos Resultantes ===\")\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "print(f\"y_test: {y_test.shape}\")\n",
    "\n",
    "# Análisis de distribución de clases en cada conjunto\n",
    "print(f\"\\n=== Distribución de Clases por Conjunto ===\")\n",
    "\n",
    "train_distribution = y_train.value_counts().sort_index()\n",
    "test_distribution = y_test.value_counts().sort_index()\n",
    "\n",
    "print(\"Conjunto de Entrenamiento:\")\n",
    "print(f\"  Clase 0 (normal): {train_distribution[0]} ({train_distribution[0]/len(y_train)*100:.2f}%)\")\n",
    "print(f\"  Clase 1 (pre-falla): {train_distribution[1]} ({train_distribution[1]/len(y_train)*100:.2f}%)\")\n",
    "print(f\"  Ratio de desbalance: {train_distribution[0]/train_distribution[1]:.1f}:1\")\n",
    "\n",
    "print(\"\\nConjunto de Prueba:\")\n",
    "print(f\"  Clase 0 (normal): {test_distribution[0]} ({test_distribution[0]/len(y_test)*100:.2f}%)\")\n",
    "print(f\"  Clase 1 (pre-falla): {test_distribution[1]} ({test_distribution[1]/len(y_test)*100:.2f}%)\")\n",
    "print(f\"  Ratio de desbalance: {test_distribution[0]/test_distribution[1]:.1f}:1\")\n",
    "\n",
    "# Visualización de la división cronológica\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Distribución temporal de la variable objetivo\n",
    "ax1.plot(range(len(y)), y.values, alpha=0.7, linewidth=0.8)\n",
    "ax1.axvline(x=split_index, color='red', linestyle='--', linewidth=2, label='Punto de División')\n",
    "ax1.set_title('División Cronológica del Dataset')\n",
    "ax1.set_xlabel('Índice Temporal')\n",
    "ax1.set_ylabel('Variable Objetivo (falla)')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Comparación de distribuciones de clases\n",
    "sets = ['Entrenamiento', 'Prueba']\n",
    "normal_counts = [train_distribution[0], test_distribution[0]]\n",
    "failure_counts = [train_distribution[1], test_distribution[1]]\n",
    "\n",
    "x = np.arange(len(sets))\n",
    "width = 0.35\n",
    "\n",
    "ax2.bar(x - width/2, normal_counts, width, label='Clase 0 (Normal)', alpha=0.8)\n",
    "ax2.bar(x + width/2, failure_counts, width, label='Clase 1 (Pre-falla)', alpha=0.8)\n",
    "ax2.set_title('Distribución de Clases por Conjunto')\n",
    "ax2.set_xlabel('Conjunto de Datos')\n",
    "ax2.set_ylabel('Número de Muestras')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(sets)\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nDivisión cronológica implementada correctamente\")\n",
    "print(\"El modelo será entrenado exclusivamente con datos históricos\")\n",
    "print(\"La evaluación se realizará sobre datos temporalmente posteriores\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
